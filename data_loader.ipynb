{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "sys.path.append('..')\n",
    "from BDDData import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the BDD_dataset class from BDDData module\n",
    "from BDDData import BDD_dataset\n",
    "\n",
    "# Reload the module to ensure we have the latest version\n",
    "importlib.reload(sys.modules['BDDData'])\n",
    "\n",
    "#Load dataframes\n",
    "bdd_data = BDD_dataset(\"raw_data/\")\n",
    "#Add column with the timestep\n",
    "bdd_data.add_timestep_id()\n",
    "#Add flags for chaotic values\n",
    "bdd_data.tag_chaotic(replace=True)\n",
    "\n",
    "#Interpolate the missing values\n",
    "bdd_data.interpolate_power()\n",
    "#Values smaller than 0 are set to 0\n",
    "bdd_data.cap_power_to_zero()\n",
    "#Normalize Patv feature to [0,1]\n",
    "bdd_data.normalize_power(min=0, max=1, method= \"MinMaxScaler\")\n",
    "#Convert df to matrix form, where only Patv is included. Then split into train, validation and test\n",
    "#The matrix contains the subset of the time series for ALL nodes, so an (TxN matrix)\n",
    "train, val, test = bdd_data.split_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the BDD_dataset class from BDDData module\n",
    "from BDDData import BDD_dataset\n",
    "\n",
    "# Reload the module to ensure we have the latest version\n",
    "importlib.reload(sys.modules['BDDData'])\n",
    "\n",
    "#Load dataframes\n",
    "bdd_data = BDD_dataset(\"raw_data/\")\n",
    "#Add flags for chaotic values\n",
    "bdd_data.tag_chaotic(replace=False)\n",
    "\n",
    "#Values smaller than 0 are set to 0\n",
    "bdd_data.cap_power_to_zero()\n",
    "#Normalize Patv feature to [0,1]\n",
    "bdd_data.normalize_power(min=0, max=1, method= \"MinMaxScaler\")\n",
    "#Add column with the timestep\n",
    "bdd_data.add_timestep_id()\n",
    "\n",
    "#import the real values\n",
    "\n",
    "#en split into traibdd_data.n, validation and test\n",
    "#The matrix contains the subset of the time series for ALL nodes, so an (TxN matrix)\n",
    "# train, val, test = bdd_data.split_df_no_missing_values(34346, 34375)\n",
    "# print(f'Train set:\\n{train}')\n",
    "# print(f'val set:\\n {val}')\n",
    "# print(f'test set: \\n{test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  275   276   277 ... 35276 35278 35279]\n"
     ]
    }
   ],
   "source": [
    "time_steps_array = bdd_data.find_complete_window()\n",
    "print(time_steps_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBDD_Dataset(data.Dataset):\n",
    "    def __init__(self, dataset, data_array, observation_window=12, forecast_window=12, starting_turbine=0, ending_turbine=133):\n",
    "        self.observation_window = int(observation_window)\n",
    "        self.forecast_window = forecast_window\n",
    "        self.window_of_interest = data_array\n",
    "        self.dataset_values = data_array\n",
    "        print(f\"window of interest\", self.window_of_interest)\n",
    "        self.starting_turbine = int(starting_turbine)\n",
    "        self.ending_turbine = int(ending_turbine)\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_of_interest)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(f\"Index: {idx}\")\n",
    "        print(self.window_of_interest)\n",
    "        window = self.window_of_interest[idx]\n",
    "        print(f\"Window: {window}\")\n",
    "        print(f\"Starting Turbine: {self.starting_turbine}\")\n",
    "        print(f\"Ending Turbine: {self.ending_turbine}\")\n",
    "        print(f\"Dataset: {self.dataset}\")\n",
    "\n",
    "        if self.dataset == \"train\":\n",
    "            features = self.dataset_values[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]].transpose()\n",
    "            print(\"pliep\")\n",
    "            labels = self.dataset_values[self.starting_turbine:self.ending_turbine+1, window[1]:window[2]].transpose()\n",
    "            print(f\"Features shape: {features.shape}\")\n",
    "            print(f\"Labels shape: {labels.shape}\")\n",
    "        elif self.dataset == \"val\":\n",
    "            features = val[self.starting_turbine:self.ending_turbine+1, window[0]:window[1]].transpose()\n",
    "            labels = val[self.starting_turbine:self.ending_turbine+1, window[1]:window[2]].transpose()\n",
    "            print(f\"Features shape: {features.shape}\")\n",
    "            print(f\"Labels shape: {labels.shape}\")\n",
    "        elif self.dataset == \"test\":\n",
    "            features = test[self.starting_turbine:self.ending_turbine+1, window[0]:window[1]].transpose()\n",
    "            labels = test[self.starting_turbine:self.ending_turbine+1, window[1]:window[2]].transpose()\n",
    "            print(f\"Features shape: {features.shape}\")\n",
    "            print(f\"Labels shape: {labels.shape}\")\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return torch.from_numpy(features).float(), torch.from_numpy(labels).float()\n",
    "\n",
    "    \n",
    "obs_window = 12\n",
    "forecast_window = 12\n",
    "val_window = 3\n",
    "\n",
    "# train_dataset = CustomBDD_Dataset(\"train\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "# train_loader = data.DataLoader(train_dataset, shuffle=True, batch_size = 100)\n",
    "# val_dataset = CustomBDD_Dataset(\"val\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "# val_loader = data.DataLoader(val_dataset, shuffle=True, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30772, 30773, 30774, 30775, 30776, 30777, 30778, 30779, 30780, 30781, 30782, 30783, 30784, 30785, 30786, 30787, 30788, 30789, 30790, 30791, 30792, 30793, 30794, 30795, 30796, 30797, 30798, 30799], [31113, 31114, 31115, 31116, 31117, 31118, 31119, 31120, 31121, 31122, 31123, 31124, 31125, 31126, 31127, 31128, 31129, 31130, 31131, 31132, 31133, 31134, 31135, 31136, 31137, 31138, 31139, 31140], [34345, 34346, 34347, 34348, 34349, 34350, 34351, 34352, 34353, 34354, 34355, 34356, 34357, 34358, 34359, 34360, 34361, 34362, 34363, 34364, 34365, 34366, 34367, 34368, 34369, 34370, 34371, 34372, 34373, 34374]]\n"
     ]
    }
   ],
   "source": [
    "obs_window = 12\n",
    "forecast_window = 12\n",
    "val_window = 3\n",
    "def find_chains(array,window_size):\n",
    "    chains = []\n",
    "    current_chain = [array[0]]\n",
    "    for i in range(1, len(array)):\n",
    "        if array[i] - array[i-1] == 1:\n",
    "            current_chain.append(array[i])\n",
    "        else:\n",
    "            if len(current_chain) > window_size:\n",
    "                chains.append(current_chain)\n",
    "            current_chain = [array[i]]\n",
    "    if len(current_chain) > window_size:\n",
    "        chains.append(current_chain)\n",
    "    return chains\n",
    "\n",
    "# Find chains with lengths greater than 24\n",
    "complete_windows = find_chains(time_steps_array,obs_window + forecast_window + val_window)\n",
    "print(complete_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38890378 0.47100228 0.48918967 ... 0.76162397 0.74722084 0.69575372]\n",
      " [0.4252275  0.4546464  0.58075838 ... 0.80498653 0.75194318 0.84254189]\n",
      " [0.5239563  0.42562954 0.3499381  ... 0.90115633 0.87420709 0.42026905]\n",
      " ...\n",
      " [0.20440071 0.2219308  0.25437455 ... 0.3094217  0.34692601 0.31369095]\n",
      " [0.1887085  0.18923817 0.25257495 ... 0.32695818 0.3418846  0.32743041]\n",
      " [0.30767954 0.30679889 0.35344795 ... 0.33667088 0.31983638 0.29808171]]\n",
      "[[0.38890378 0.47100228 0.48918967 ... 0.76162397 0.74722084 0.69575372]\n",
      " [0.4252275  0.4546464  0.58075838 ... 0.80498653 0.75194318 0.84254189]\n",
      " [0.5239563  0.42562954 0.3499381  ... 0.90115633 0.87420709 0.42026905]\n",
      " ...\n",
      " [0.20440071 0.2219308  0.25437455 ... 0.3094217  0.34692601 0.31369095]\n",
      " [0.1887085  0.18923817 0.25257495 ... 0.32695818 0.3418846  0.32743041]\n",
      " [0.30767954 0.30679889 0.35344795 ... 0.33667088 0.31983638 0.29808171]]\n",
      "Train shape: (134, 12)\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x13d6105d0>\n"
     ]
    }
   ],
   "source": [
    "train, val, test = bdd_data.split_df_custom(complete_windows, chain_index=1, obs_window = 12, forecast_window = 12, val_window = 3)\n",
    "\n",
    "print(train)\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "\n",
    "train_loader = data.DataLoader(train, shuffle=True, batch_size = 10)\n",
    "val_loader = data.DataLoader(val, shuffle=True, batch_size = 10)\n",
    "\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "tensor([[0.2097, 0.2188, 0.2551, 0.2123, 0.1716, 0.2777, 0.2702, 0.1920, 0.2172,\n",
      "         0.3043, 0.3098, 0.3266],\n",
      "        [0.3729, 0.3645, 0.4804, 0.3739, 0.3280, 0.6268, 0.5986, 0.5789, 0.5256,\n",
      "         0.2263, 0.3033, 0.3491],\n",
      "        [0.2300, 0.2253, 0.2698, 0.2475, 0.2131, 0.2250, 0.2072, 0.1865, 0.2189,\n",
      "         0.2522, 0.2132, 0.2584],\n",
      "        [0.3009, 0.3395, 0.3631, 0.3141, 0.2986, 0.2916, 0.2116, 0.2324, 0.2996,\n",
      "         0.3341, 0.3352, 0.3447],\n",
      "        [0.1887, 0.1892, 0.2526, 0.2777, 0.2801, 0.2611, 0.2682, 0.2912, 0.3061,\n",
      "         0.3270, 0.3419, 0.3274],\n",
      "        [0.3208, 0.4518, 0.4545, 0.3942, 0.5770, 0.5558, 0.7255, 0.7638, 0.7693,\n",
      "         0.8171, 0.8205, 0.9060],\n",
      "        [0.2542, 0.2912, 0.3413, 0.3191, 0.2880, 0.2563, 0.2525, 0.2220, 0.2607,\n",
      "         0.2467, 0.1992, 0.1912],\n",
      "        [0.2804, 0.2770, 0.3022, 0.3299, 0.3077, 0.3035, 0.2915, 0.2662, 0.2517,\n",
      "         0.2796, 0.2698, 0.2617],\n",
      "        [0.3467, 0.3815, 0.4555, 0.4634, 0.4184, 0.4560, 0.4521, 0.5532, 0.5683,\n",
      "         0.3803, 0.2450, 0.3248],\n",
      "        [0.3119, 0.3459, 0.3638, 0.4069, 0.4166, 0.5116, 0.6855, 0.6401, 0.6283,\n",
      "         0.6840, 0.4163, 0.2469]], dtype=torch.float64)\n",
      "Batch shape: torch.Size([10, 12])\n",
      "Batch 2:\n",
      "tensor([[0.3129, 0.2626, 0.2574, 0.2526, 0.2172, 0.2016, 0.1849, 0.1524, 0.2044,\n",
      "         0.2303, 0.1803, 0.2535],\n",
      "        [0.2461, 0.2644, 0.2494, 0.2680, 0.2180, 0.1951, 0.3404, 0.2809, 0.1577,\n",
      "         0.1701, 0.1840, 0.2325],\n",
      "        [0.3889, 0.4710, 0.4892, 0.5344, 0.5041, 0.5434, 0.6709, 0.6609, 0.7277,\n",
      "         0.7616, 0.7472, 0.6958],\n",
      "        [0.2712, 0.3164, 0.3584, 0.3636, 0.3700, 0.3450, 0.3375, 0.2997, 0.3310,\n",
      "         0.3315, 0.3269, 0.3299],\n",
      "        [0.3414, 0.3815, 0.4621, 0.6053, 0.5098, 0.8458, 0.8746, 0.9259, 0.9495,\n",
      "         0.9269, 0.6494, 0.2854],\n",
      "        [0.2506, 0.2920, 0.2893, 0.3266, 0.3213, 0.3062, 0.2878, 0.2679, 0.2659,\n",
      "         0.2778, 0.2663, 0.2856],\n",
      "        [0.2048, 0.1980, 0.2439, 0.2488, 0.2658, 0.2119, 0.2103, 0.2475, 0.2420,\n",
      "         0.3193, 0.2898, 0.2772],\n",
      "        [0.3234, 0.2805, 0.3247, 0.3314, 0.3791, 0.3330, 0.3139, 0.3701, 0.4362,\n",
      "         0.5372, 0.2910, 0.2249],\n",
      "        [0.3650, 0.3351, 0.3403, 0.4099, 0.3247, 0.2251, 0.3303, 0.4370, 0.4273,\n",
      "         0.2147, 0.2405, 0.2318],\n",
      "        [0.3307, 0.3484, 0.3694, 0.3616, 0.3675, 0.3452, 0.3255, 0.2902, 0.3234,\n",
      "         0.3279, 0.3065, 0.2989]], dtype=torch.float64)\n",
      "Batch shape: torch.Size([10, 12])\n",
      "Batch 3:\n",
      "tensor([[0.2553, 0.3098, 0.3427, 0.4554, 0.3712, 0.3403, 0.3513, 0.5625, 0.5945,\n",
      "         0.5024, 0.5156, 0.4183],\n",
      "        [0.3081, 0.2256, 0.2689, 0.2599, 0.1859, 0.2267, 0.1989, 0.2088, 0.2313,\n",
      "         0.2439, 0.2178, 0.2539],\n",
      "        [0.1968, 0.2510, 0.2242, 0.3256, 0.4129, 0.4548, 0.5716, 0.3995, 0.3571,\n",
      "         0.4150, 0.1910, 0.2413],\n",
      "        [0.3746, 0.3246, 0.3873, 0.4611, 0.4102, 0.4154, 0.6544, 0.6859, 0.8699,\n",
      "         0.7723, 0.7009, 0.2945],\n",
      "        [0.1796, 0.1920, 0.2076, 0.2186, 0.2000, 0.1894, 0.2004, 0.1948, 0.1971,\n",
      "         0.2212, 0.2722, 0.2362],\n",
      "        [0.2770, 0.3179, 0.3624, 0.5378, 0.5102, 0.6770, 0.7870, 0.5498, 0.6490,\n",
      "         0.6348, 0.1695, 0.2423],\n",
      "        [0.2720, 0.2962, 0.3154, 0.3648, 0.2342, 0.2914, 0.5251, 0.4096, 0.2654,\n",
      "         0.2523, 0.2504, 0.2660],\n",
      "        [0.2140, 0.2316, 0.2673, 0.2276, 0.2244, 0.2020, 0.1930, 0.1706, 0.1892,\n",
      "         0.2285, 0.2012, 0.2393],\n",
      "        [0.1969, 0.2208, 0.2574, 0.2328, 0.1952, 0.2053, 0.2510, 0.2439, 0.2982,\n",
      "         0.3339, 0.3035, 0.2557],\n",
      "        [0.3167, 0.3308, 0.3843, 0.3157, 0.2677, 0.3125, 0.5698, 0.2336, 0.2259,\n",
      "         0.3187, 0.3206, 0.3134]], dtype=torch.float64)\n",
      "Batch shape: torch.Size([10, 12])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Iterate through a few batches from the train loader\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(batch)\n",
    "    print(f\"Batch shape: {batch.shape}\")\n",
    "    \n",
    "    # Limit to a few batches\n",
    "    if i == 2:  # For example, stop after 3 batches\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

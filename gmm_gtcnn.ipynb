{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:17:59.291587300Z",
     "start_time": "2024-06-28T08:17:59.273723600Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "sys.path.append('..')\n",
    "from BDDData import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import circulant\n",
    "from product_graph import *\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:17:59.292585500Z",
     "start_time": "2024-06-28T08:17:59.280270900Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:06.923220600Z",
     "start_time": "2024-06-28T08:17:59.292585500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 24624)\n"
     ]
    }
   ],
   "source": [
    "#Load dataframes\n",
    "bdd_data = BDD_dataset(\"raw_data/BDDdata/\")\n",
    "#Add column with the timestep\n",
    "bdd_data.add_timestep_id()\n",
    "#Add flags for chaotic values\n",
    "bdd_data.tag_chaotic(replace=True)\n",
    "#Compute the mod for the nazelle and wind angles\n",
    "bdd_data.angle_mod()\n",
    "\n",
    "# ! Don't interpolate this data\n",
    "# ! Missing values remain NaN\n",
    "# #Interpolate the missing values\n",
    "# bdd_data.interpolate_power()\n",
    "\n",
    "#Values smaller than 0 are set to 0\n",
    "bdd_data.cap_power_to_zero()\n",
    "#Normalize Patv feature to [0,1]\n",
    "bdd_data.normalize_power(min=0, max=1, method= \"MinMaxScaler\")\n",
    "#Convert df to matrix form, where only Patv is included. Then split into train, validation and test\n",
    "#The matrix contains the subset of the time series for ALL nodes, so an (TxN matrix)\n",
    "train, val, test = bdd_data.split_df()\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:06.944305100Z",
     "start_time": "2024-06-28T08:18:06.925215700Z"
    }
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(42)\n",
    "# consider a p percentage of the data\n",
    "p = 0.01\n",
    "train_mask = np.random.choice(train.shape[1], int(train.shape[1] * p), replace=False)\n",
    "val_mask = np.random.choice(val.shape[1], int(val.shape[1] * p), replace=False)\n",
    "test_mask = np.random.choice(test.shape[1], int(test.shape[1] * p), replace=False)\n",
    "\n",
    "train = train[:, train_mask]\n",
    "val = val[:, val_mask]\n",
    "test = test[:, test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.231619300Z",
     "start_time": "2024-06-28T08:18:06.950289300Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomBDD_Dataset(data.Dataset):\n",
    "    def __init__(self, dataset, observation_window=12, forecast_window=12, starting_turbine = 0,  ending_turbine=133):\n",
    "        self.observation_window = observation_window\n",
    "        self.forecast_window = forecast_window\n",
    "        length = eval(f'len({dataset}[0])')#Retrieves length of dataset\n",
    "        bdd_data.get_observation_forecasting_window(time_series_len=length, observation_steps=self.observation_window, forecast_steps=self.forecast_window)#Generates obs window\n",
    "        self.window_of_interest =  bdd_data.sliding_indices[str(self.observation_window)+\",\"+str(self.forecast_window)]#Retrieves windows\n",
    "        self.starting_turbine = starting_turbine\n",
    "        self.ending_turbine = ending_turbine  \n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_of_interest)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = self.window_of_interest[idx]\n",
    "        if self.dataset == \"train\":\n",
    "            features = train[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]].transpose().reshape(-1, 1)\n",
    "            labels = train[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]].transpose().reshape(-1, 1)\n",
    "        elif self.dataset == \"val\":\n",
    "            features = val[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]].transpose().reshape(-1, 1)\n",
    "            labels = val[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]].transpose().reshape(-1, 1)\n",
    "        elif self.dataset == \"test\":\n",
    "            features = test[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]].transpose().reshape(-1, 1)\n",
    "            labels = test[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]].transpose().reshape(-1, 1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return torch.from_numpy(features).float(), torch.from_numpy(labels).float()\n",
    "    \n",
    "obs_window = 12\n",
    "forecast_window = 12\n",
    "batch_size = 100\n",
    "\n",
    "train_dataset = CustomBDD_Dataset(\"train\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "train_loader = data.DataLoader(train_dataset, shuffle=True, batch_size = batch_size)\n",
    "val_dataset = CustomBDD_Dataset(\"val\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "val_loader = data.DataLoader(val_dataset, shuffle=True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.239067200Z",
     "start_time": "2024-06-28T08:18:07.231619300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([100, 1608, 1])\n",
      "y.shape=torch.Size([100, 1608, 1])\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "print(f\"{x.shape=}\\n{y.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.298318500Z",
     "start_time": "2024-06-28T08:18:07.240064200Z"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.read_gml('data/spatial_graph_2000.gml')\n",
    "adj_mat = nx.adjacency_matrix(G)\n",
    "adj_mat = nx.to_numpy_array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.303817700Z",
     "start_time": "2024-06-28T08:18:07.299314900Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_time_graph(window: int, directed: bool, cyclic: bool):\n",
    "    \"\"\"\n",
    "    Circulant matrix as in https://arxiv.org/pdf/1712.00468.pdf (eq. 7)\n",
    "    \"\"\"\n",
    "    if window <= 1:\n",
    "        raise Exception(\"Ehm..\")\n",
    "    adjacency = circulant([0, 1] + [0 for _ in range(window-2)])\n",
    "    if not cyclic:\n",
    "        adjacency[0, window-1] = 0\n",
    "    if not directed:\n",
    "        adjacency += adjacency.transpose()\n",
    "\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.400034400Z",
     "start_time": "2024-06-28T08:18:07.304816500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timegraph = build_time_graph(12,True,False)\n",
    "print(timegraph)\n",
    "tg = nx.from_numpy_array(timegraph)\n",
    "nx.draw(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.405694100Z",
     "start_time": "2024-06-28T08:18:07.403192600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the adjacency matrix\n",
    "S = normalize_adjacency(torch.tensor(adj_mat)).float()\n",
    "S_t = torch.tensor(timegraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.552057Z",
     "start_time": "2024-06-28T08:18:07.407687500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cartesian\n",
    "pg = build_parametric_product_graph(S_t, S, 0, 1, 1, 1).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.558928500Z",
     "start_time": "2024-06-28T08:18:07.515055100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1608, 1608])\n"
     ]
    }
   ],
   "source": [
    "print(pg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.558928500Z",
     "start_time": "2024-06-28T08:18:07.522628800Z"
    }
   },
   "outputs": [],
   "source": [
    "# FOR GMM Implementation\n",
    "# ! Taken from the paper.\n",
    "def ex_relu(mu, sigma):\n",
    "    is_zero = sigma == 0\n",
    "    sigma = torch.where(is_zero, torch.tensor(1e-10, device=sigma.device), sigma)\n",
    "    sqrt_sigma = torch.sqrt(sigma)\n",
    "    w = torch.div(mu, sqrt_sigma)\n",
    "    nr_values = sqrt_sigma * (\n",
    "            torch.div(torch.exp(torch.div(-w * w, 2)), np.sqrt(2 * np.pi))\n",
    "            + torch.div(w, 2) * (1 + torch.erf(torch.div(w, np.sqrt(2))))\n",
    "    )\n",
    "    nr_values = torch.where(is_zero, F.relu(mu), nr_values)\n",
    "    return nr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.559926300Z",
     "start_time": "2024-06-28T08:18:07.552057Z"
    }
   },
   "outputs": [],
   "source": [
    "class GMMGCNNLayer(nn.Module):\n",
    "    \"\"\"This extends the GMMGCNLayer, adding order q. Forward pass LMW becomes Sum over q of L^qMW.\"\"\"\n",
    "\n",
    "    def _init_gmm(self, features, K):\n",
    "        # Simply impute the values once for initialization of the gmm.\n",
    "        # Keep empty features\n",
    "        imputer = SimpleImputer(\n",
    "            missing_values=np.nan, strategy=\"mean\", keep_empty_features=True\n",
    "        )\n",
    "        imputed_x = imputer.fit_transform(features)\n",
    "        gmm = GaussianMixture(n_components=K, covariance_type=\"diag\").fit(imputed_x)\n",
    "        return gmm\n",
    "\n",
    "    # ! Taken from the paper.\n",
    "    def _calc_responsibility(self, mean_mat, variances):\n",
    "        dim = self.in_features\n",
    "        log_n = (\n",
    "                (-1 / 2)\n",
    "                * torch.sum(\n",
    "            torch.pow(mean_mat - self.mu.unsqueeze(1), 2) / variances.unsqueeze(1),\n",
    "            2,\n",
    "        )\n",
    "                - (dim / 2) * np.log(2 * np.pi)\n",
    "                - (1 / 2) * torch.sum(self.sigma)\n",
    "        )\n",
    "        log_prob = self.pi.unsqueeze(1) + log_n\n",
    "        return torch.softmax(log_prob, dim=0)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        num_components,\n",
    "        all_features,\n",
    "        all_A,\n",
    "        order,\n",
    "        device=\"cpu\",\n",
    "    ) -> None:\n",
    "        super(GMMGCNNLayer, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.num_components = num_components\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        # All feature data, used for initialization of the GMM.\n",
    "        self.all_features = all_features\n",
    "\n",
    "        self.all_A = all_A\n",
    "        self.order = order\n",
    "\n",
    "        # Initialize the weights\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(order+1, in_features, out_features))\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "\n",
    "        # Initialize GMM and its parameters (we're going to learn these)\n",
    "        self.gmm = self._init_gmm(self.all_features, self.num_components)\n",
    "        self.pi = nn.Parameter(torch.FloatTensor(np.log(self.gmm.weights_))).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.mu = nn.Parameter(torch.FloatTensor(self.gmm.means_).to(self.device))\n",
    "        self.sigma = nn.Parameter(\n",
    "            torch.FloatTensor(np.log(self.gmm.covariances_)).to(self.device)\n",
    "        )\n",
    "\n",
    "        # Prepare shifts for all orders in one go\n",
    "        self.shifts = [torch.matrix_power(all_A, q) for q in range(self.order+1)]\n",
    "        # self.A2s = [torch.mul(self.shifts[q], self.shifts[q]).to(self.device) for q in range(self.order+1)]\n",
    "        self.A2s = []\n",
    "        for q1 in range(order+1):\n",
    "            for q2 in range(order+1):\n",
    "                 self.A2s.append(torch.spmm(self.shifts[q1], self.shifts[q2]))\n",
    "\n",
    "    def forward(self, features):\n",
    "        batch_size = features.size(0)\n",
    "        tensor_list = []\n",
    "        for i in range(batch_size):\n",
    "            out = self._forward(features[i])\n",
    "            tensor_list.append(out)\n",
    "        return torch.stack(tensor_list, dim=0)\n",
    "\n",
    "    def _forward(self, features):\n",
    "        x_imp = features.repeat(self.num_components, 1, 1)\n",
    "        x_isnan = torch.isnan(x_imp)\n",
    "        variances = torch.exp(self.sigma)\n",
    "        # M\n",
    "        mean_mat = torch.where(\n",
    "            x_isnan, self.mu.repeat((features.size(0), 1, 1)).permute(1, 0, 2), x_imp\n",
    "        )\n",
    "        # S\n",
    "        var_mat = torch.where(\n",
    "            x_isnan,\n",
    "            variances.repeat((features.size(0), 1, 1)).permute(1, 0, 2),\n",
    "            torch.zeros(size=x_imp.size(), device=self.device, requires_grad=True),\n",
    "        )\n",
    "\n",
    "        # M^kW\n",
    "        transform_x = []\n",
    "        for q in range(self.order+1):\n",
    "            transform_x.append(torch.matmul(mean_mat, self.weights[q]))\n",
    "        # Becomes: # M^k W_q\n",
    "        # S^k (W * W)\n",
    "        # transform_covs = torch.matmul(var_mat, self.weight * self.weight)\n",
    "        # Becomes:\n",
    "        transform_covs = []\n",
    "        for q1 in range(self.order+1):\n",
    "            for q2 in range(self.order+1):\n",
    "                transform_covs.append(torch.matmul(var_mat, self.weights[q1] * self.weights[q2]))\n",
    "        \n",
    "        conv_x = []\n",
    "        conv_covs = []\n",
    "\n",
    "        # for component_x in transform_x:\n",
    "        for component_index in range(self.num_components):\n",
    "            # First:\n",
    "            # LM^kW\n",
    "            # conv_x.append(torch.spmm(shift, component_x))\n",
    "\n",
    "            # Becomes:\n",
    "            # sum over Q of (L^q M^k W)\n",
    "\n",
    "            # Second iteration, becomes:\n",
    "            # Add weights for every layer.\n",
    "            # sum over Q of (L^q M^k W_q)\n",
    "            out = torch.stack([torch.spmm(self.shifts[q], transform_x[q][component_index]) for q in range(self.order+1)]).mean(dim=0)\n",
    "\n",
    "            conv_x.append(out)\n",
    "\n",
    "        # Transform_covs used to be shape: torch.Size([5, 1608, 1])\n",
    "        # for component_covs in transform_covs:\n",
    "        for component_index in range(self.num_components):\n",
    "            # First:\n",
    "            # (L*L) S^k\n",
    "            # conv_covs.append(torch.spmm(self.A2, component_covs))\n",
    "\n",
    "            # Becomes:\n",
    "            # sum over Q of ( (L^q * L^q) S^k W * W)\n",
    "            # out = torch.stack([torch.spmm(self.A2s[q], component_covs) for q in range(self.order)]).mean(dim=0)\n",
    "\n",
    "            # Second iteration, becomes:\n",
    "            # sum over Q of ( (L^q1 * L^q2) S^k W_q1 * W_q1)\n",
    "            out = []\n",
    "            for q1 in range(self.order+1):\n",
    "                for q2 in range(self.order+1):\n",
    "                    # Index where we retrieve the precomputed tensors from\n",
    "                    index = q1*(self.order+1)+q2\n",
    "                    component_cov = transform_covs[index][component_index]\n",
    "                    weights = self.weights[q1] * self.weights[q2]\n",
    "                    # out.append(torch.spmm(torch.spmm(torch.spmm(torch.matrix_power(self.all_A, q1), torch.matrix_power(self.all_A, q2)), component_cov), weights.T))\n",
    "                    out.append(torch.spmm(torch.spmm(self.A2s[index], component_cov), weights.T))\n",
    "                \n",
    "            conv_covs.append(torch.stack(out).mean(dim=0))\n",
    "\n",
    "        transform_x = torch.stack(conv_x, dim=0)\n",
    "        transform_covs = torch.stack(conv_covs, dim=0)\n",
    "        # ReLU[N(M, S)]\n",
    "        expected_x = ex_relu(transform_x, transform_covs)\n",
    "\n",
    "        # calculate responsibility\n",
    "        gamma = self._calc_responsibility(mean_mat, variances)\n",
    "        # ReLU[(LXW)]\n",
    "        expected_x = torch.sum(expected_x * gamma.unsqueeze(2), dim=0)\n",
    "        # Check for NaNs\n",
    "        if torch.isnan(expected_x).any():\n",
    "            print(\"NaN detected in expected_x:\")\n",
    "        return expected_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.567184800Z",
     "start_time": "2024-06-28T08:18:07.562918500Z"
    }
   },
   "outputs": [],
   "source": [
    "class GCNNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, matrix_powers, order):\n",
    "        super(GCNNLayer, self).__init__()\n",
    "        self.matrix_powers = matrix_powers\n",
    "        self.order = order\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(in_features, out_features, order+1))\n",
    "        # use Xavier initialization to match variance of input with output\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def forward(self, features):\n",
    "        batch_size = features.size(0)\n",
    "        output_dim = self.weights.size(1)\n",
    "        device = features.device\n",
    "\n",
    "        out = torch.zeros((batch_size, features.size(1), output_dim), device=device)\n",
    "        for k in range(self.order+1):\n",
    "            weighted = torch.bmm(features, self.weights[:, :, k].unsqueeze(0).repeat(batch_size, 1, 1))\n",
    "            shifted = torch.bmm(self.matrix_powers[k].unsqueeze(0).repeat(batch_size, 1, 1).to(device), weighted)\n",
    "            out += shifted\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.582713900Z",
     "start_time": "2024-06-28T08:18:07.577159300Z"
    }
   },
   "outputs": [],
   "source": [
    "class GMMGCNN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, obs_size, pred_size, hid_sizes, num_components, all_features, all_A, order\n",
    "    ):\n",
    "        super(GMMGCNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # First layer is a GCNN that incorporates the GMM.\n",
    "        self.layers.append(\n",
    "            GMMGCNNLayer(\n",
    "                obs_size, hid_sizes[0], num_components, all_features, all_A, order, device=device\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Later layers are regular GCNNs.\n",
    "        # Precompute the matrix powers.\n",
    "        matrix_powers = []\n",
    "        for q in range(order+1):\n",
    "            matrix_powers.append(torch.matrix_power(all_A, q))\n",
    "        # num_hid hidden layers of size hid_size\n",
    "        for i in range(len(hid_sizes) - 1):\n",
    "            self.layers.append(GCNNLayer(hid_sizes[i], hid_sizes[i + 1], matrix_powers, order))\n",
    "        self.layers.append(GCNNLayer(hid_sizes[-1], pred_size, matrix_powers, order))\n",
    "\n",
    "    def forward(self, features):\n",
    "        # print(f\"forward in: {features}\")\n",
    "        # No relu for the first layer, it is a GMM layer.\n",
    "        temp = self.layers[0].forward(features)\n",
    "        # print(f\"after gmmgcnn layer: {temp}\")\n",
    "        for layer in self.layers[1:-1]:\n",
    "            # use relu activation function\n",
    "            # No shift operator necessary for the GCNN, it is already added to the initatialization.\n",
    "            temp = F.relu(layer(temp))\n",
    "        # Last layer no relu\n",
    "        return self.layers[-1](temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T08:18:07.630513600Z",
     "start_time": "2024-06-28T08:18:07.585706Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MaskedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        # Create a mask that is 1 for non-NaN entries and 0 for NaN entries\n",
    "        mask = ~torch.isnan(target)\n",
    "        # Apply the mask to only keep non-NaN elements\n",
    "        out = prediction[mask]\n",
    "        tar = target[mask]\n",
    "        # Calculate MSE Loss on non-NaN elements\n",
    "        return nn.functional.mse_loss(out, tar)\n",
    "\n",
    "def train_epoch_gcnn(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_epoch_gcnn(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def train_gcnn(model, shift, num_epochs, criterion, train_loader, test_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Model training\n",
    "        train_loss = train_epoch_gcnn(model, train_loader, optimizer, criterion)\n",
    "\n",
    "        # Model validation\n",
    "        val_loss = evaluate_epoch_gcnn(model, test_loader, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(\n",
    "                \"epoch:\",\n",
    "                epoch,\n",
    "                \"\\t training loss:\",\n",
    "                np.round(train_loss, 4),\n",
    "                \"\\t validation loss:\",\n",
    "                np.round(val_loss, 4),\n",
    "            )\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Model training took {elapsed_time:.3f} seconds\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T09:16:15.070199600Z",
     "start_time": "2024-06-28T08:18:07.602588900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created GMM-GTCNN model with 33295 parameters:\n",
      "layers.0.weights torch.Size([2, 1, 128])\n",
      "layers.0.pi torch.Size([5])\n",
      "layers.0.mu torch.Size([5, 1])\n",
      "layers.0.sigma torch.Size([5, 1])\n",
      "layers.1.weights torch.Size([128, 128, 2])\n",
      "layers.2.weights torch.Size([128, 1, 2])\n",
      "epoch: 1 \t training loss: 214.1627 \t validation loss: 1.9655\n",
      "epoch: 2 \t training loss: 7.7569 \t validation loss: 0.0514\n",
      "epoch: 3 \t training loss: 0.1345 \t validation loss: 0.0633\n",
      "epoch: 4 \t training loss: 0.1127 \t validation loss: 0.0615\n",
      "epoch: 5 \t training loss: 0.1094 \t validation loss: 0.0689\n",
      "epoch: 6 \t training loss: 0.0973 \t validation loss: 0.0578\n",
      "epoch: 7 \t training loss: 0.0999 \t validation loss: 0.0678\n",
      "epoch: 8 \t training loss: 0.0907 \t validation loss: 0.0549\n",
      "epoch: 9 \t training loss: 0.0963 \t validation loss: 0.0599\n",
      "epoch: 10 \t training loss: 0.0956 \t validation loss: 0.0571\n",
      "Model training took 193.233 seconds\n"
     ]
    }
   ],
   "source": [
    "all_features = train.reshape(-1, 1)\n",
    "all_A = pg.to(device)\n",
    "\n",
    "n_components = 5\n",
    "order = 1\n",
    "num_epochs = 10\n",
    "model = GMMGCNN(obs_size=1, pred_size=1, hid_sizes=[128, 128], num_components=n_components, all_features=all_features, all_A=all_A, order=order).to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Created GMM-GTCNN model with {pytorch_total_params} parameters:\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.size())\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_losses = train_gcnn(model, all_A, num_epochs, MaskedMSELoss(), train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T12:54:54.006087800Z",
     "start_time": "2024-06-28T12:54:53.980157Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'results/gmm_gcnn_e=10_d=1.0_k=1_mm=5[128,128,1].pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse-ml4gd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

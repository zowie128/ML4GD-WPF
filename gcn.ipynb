{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:15.763238Z",
     "start_time": "2024-06-25T08:07:07.055545Z"
    }
   },
   "source": [
    "import sys\n",
    "import csv\n",
    "sys.path.append('..')\n",
    "from BDDData import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import circulant\n",
    "from product_graph import *\n",
    "from utils import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:22:42.943854Z",
     "start_time": "2024-06-25T08:22:30.445821Z"
    }
   },
   "source": [
    "#Load dataframes\n",
    "bdd_data = BDD_dataset(\"raw_data/BDDdata/\")\n",
    "#Add column with the timestep\n",
    "bdd_data.add_timestep_id()\n",
    "#Add flags for chaotic values\n",
    "bdd_data.tag_chaotic(replace=True)\n",
    "#Compute the mod for the nazelle and wind angles\n",
    "bdd_data.angle_mod()\n",
    "#Interpolate the missing values\n",
    "bdd_data.interpolate_power()\n",
    "#Values smaller than 0 are set to 0\n",
    "bdd_data.cap_power_to_zero()\n",
    "#Normalize Patv feature to [0,1]\n",
    "bdd_data.normalize_power(min=0, max=1, method= \"MinMaxScaler\")\n",
    "#Convert df to matrix form, where only Patv is included. Then split into train, validation and test\n",
    "#The matrix contains the subset of the time series for ALL nodes, so an (TxN matrix)\n",
    "train, val, test = bdd_data.split_df()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:22:42.948622Z",
     "start_time": "2024-06-25T08:22:42.944609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = train[:,:1000]\n",
    "val = val[:, :1000]\n",
    "test = test[:, :1000]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:22:42.961408Z",
     "start_time": "2024-06-25T08:22:42.949634Z"
    }
   },
   "source": [
    "class CustomBDD_Dataset(data.Dataset):\n",
    "    def __init__(self, dataset, observation_window=12, forecast_window=12, starting_turbine = 0,  ending_turbine=133):\n",
    "        self.observation_window = observation_window\n",
    "        self.forecast_window = forecast_window\n",
    "        length = eval(f'len({dataset}[0])')#Retrieves length of dataset\n",
    "        bdd_data.get_observation_forecasting_window(time_series_len=length, observation_steps=self.observation_window, forecast_steps=self.forecast_window)#Generates obs window\n",
    "        self.window_of_interest =  bdd_data.sliding_indices[str(self.observation_window)+\",\"+str(self.forecast_window)]#Retrieves windows\n",
    "        self.starting_turbine = starting_turbine\n",
    "        self.ending_turbine = ending_turbine  \n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_of_interest)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = self.window_of_interest[idx]\n",
    "        if self.dataset == \"train\":\n",
    "            features = train[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]]\n",
    "            labels = train[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]]\n",
    "        elif self.dataset == \"val\":\n",
    "            features = val[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]]\n",
    "            labels = val[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]]\n",
    "        elif self.dataset == \"test\":\n",
    "            features = test[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]]\n",
    "            labels = test[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return torch.from_numpy(features).float(), torch.from_numpy(labels).float()\n",
    "    \n",
    "obs_window = 12\n",
    "forecast_window = 12\n",
    "batch_size = 100\n",
    "\n",
    "train_dataset = CustomBDD_Dataset(\"train\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "train_loader = data.DataLoader(train_dataset, shuffle=True, batch_size = batch_size)\n",
    "val_dataset = CustomBDD_Dataset(\"val\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "val_loader = data.DataLoader(val_dataset, shuffle=True, batch_size = batch_size)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:22:42.974378Z",
     "start_time": "2024-06-25T08:22:42.963421Z"
    }
   },
   "source": [
    "x,y = next(iter(train_loader))\n",
    "print(f\"{x.shape=}\\n{y.shape=}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([100, 134, 12])\n",
      "y.shape=torch.Size([100, 134, 12])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:22:43.052111Z",
     "start_time": "2024-06-25T08:22:42.975419Z"
    }
   },
   "source": [
    "G = nx.read_gml('data/spatial_graph_2000.gml')\n",
    "adj_mat = nx.adjacency_matrix(G)\n",
    "adj_mat = nx.to_numpy_array(G)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:22:43.128720Z",
     "start_time": "2024-06-25T08:22:43.053155Z"
    }
   },
   "source": "S = normalize_adjacency(torch.tensor(adj_mat)).float()",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:22:43.136619Z",
     "start_time": "2024-06-25T08:22:43.129725Z"
    }
   },
   "source": [
    "print(adj_mat.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 134)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:33:20.567461Z",
     "start_time": "2024-06-25T08:33:20.557815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        # use Xavier initialization to match variance of input with output\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def forward(self, shift, features):    \n",
    "        batch_size = features.size(0)\n",
    "        weights = self.weights.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        weighted = features.bmm(weights)\n",
    "        shifted = shift.unsqueeze(0).repeat(batch_size, 1, 1)        \n",
    "        return shifted.bmm(weighted)\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, obs_size, pred_size, hid_sizes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input layer of size obs_size\n",
    "        self.layers.append(GCNLayer(obs_size, hid_sizes[0]))\n",
    "        # num_hid hidden layers of size hid_size\n",
    "        for i in range(len(hid_sizes)-1):\n",
    "            self.layers.append(GCNLayer(hid_sizes[i], hid_sizes[i+1]))\n",
    "        # fully connected layer to get  output of dim pred_size\n",
    "        self.layers.append(nn.Linear(hid_sizes[-1], pred_size))\n",
    "\n",
    "    def forward(self, shift, features):\n",
    "        temp = features\n",
    "        for layer in self.layers[:-1]:\n",
    "            # use relu activation function\n",
    "            temp = F.relu(layer(shift, temp))\n",
    "        return self.layers[-1](temp)\n",
    "    \n",
    "model = GCN(obs_window, forecast_window, [128,128])"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:33:26.507288Z",
     "start_time": "2024-06-25T08:33:21.236388Z"
    }
   },
   "source": [
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(S,x)\n",
    "        loss = torch.nn.functional.mse_loss(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate_epoch(model, loader, device='cpu'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        outputs = model(S,x)\n",
    "        loss = torch.nn.functional.mse_loss(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs = 100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "        val_loss = evaluate_epoch(model, val_loader, device=device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"epoch:\",epoch, \"\\t training loss:\", np.round(train_loss,4),\n",
    "                  \"\\t validation loss:\", np.round(val_loss,4))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Model training took {elapsed_time:.3f} seconds')\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \t training loss: 16.303 \t validation loss: 0.0707\n",
      "epoch: 2 \t training loss: 0.1018 \t validation loss: 0.0925\n",
      "epoch: 3 \t training loss: 0.0906 \t validation loss: 0.0828\n",
      "epoch: 4 \t training loss: 0.0778 \t validation loss: 0.0682\n",
      "epoch: 5 \t training loss: 0.0653 \t validation loss: 0.0493\n",
      "epoch: 6 \t training loss: 0.05 \t validation loss: 0.0359\n",
      "epoch: 7 \t training loss: 0.0427 \t validation loss: 0.0306\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 52\u001B[0m\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel training took \u001B[39m\u001B[38;5;132;01m{\u001B[39;00melapsed_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train_losses, val_losses\n\u001B[1;32m---> 52\u001B[0m train_losses, val_losses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[20], line 39\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, val_loader, num_epochs)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, num_epochs\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     38\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train_epoch(model, train_loader, optimizer, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m---> 39\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[0;32m     41\u001B[0m     val_losses\u001B[38;5;241m.\u001B[39mappend(val_loss)\n",
      "Cell \u001B[1;32mIn[20], line 24\u001B[0m, in \u001B[0;36mevaluate_epoch\u001B[1;34m(model, loader, device)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x,y \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[0;32m     23\u001B[0m     x,y \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(device), y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 24\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mS\u001B[49m\u001B[43m,\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mmse_loss(outputs, y)\n\u001B[0;32m     26\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\Desktop\\Machine Learning for Graph Data\\Project\\repo\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Machine Learning for Graph Data\\Project\\repo\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[19], line 37\u001B[0m, in \u001B[0;36mGCN.forward\u001B[1;34m(self, shift, features)\u001B[0m\n\u001B[0;32m     34\u001B[0m temp \u001B[38;5;241m=\u001B[39m features\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;66;03m# use relu activation function\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m     temp \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshift\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemp\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m](temp)\n",
      "File \u001B[1;32m~\\Desktop\\Machine Learning for Graph Data\\Project\\repo\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Machine Learning for Graph Data\\Project\\repo\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[19], line 15\u001B[0m, in \u001B[0;36mGCNLayer.forward\u001B[1;34m(self, shift, features)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, shift, features):    \n\u001B[0;32m     14\u001B[0m     batch_size \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m     weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mrepeat(batch_size, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     16\u001B[0m     weighted \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39mbmm(weights)\n\u001B[0;32m     17\u001B[0m     shifted \u001B[38;5;241m=\u001B[39m shift\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mrepeat(batch_size, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)        \n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:30.630268600Z",
     "start_time": "2024-06-29T22:23:30.622213Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from BDDData import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import networkx as nx\n",
    "from graph.product_graph import *\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:30.654204800Z",
     "start_time": "2024-06-29T22:23:30.624209500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.807925300Z",
     "start_time": "2024-06-29T22:23:30.631266200Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load dataframes\n",
    "bdd_data = BDD_dataset(\"../raw_data/BDDdata/\")\n",
    "#Add column with the timestep\n",
    "bdd_data.add_timestep_id()\n",
    "#Add flags for chaotic values\n",
    "bdd_data.tag_chaotic(replace=True)\n",
    "#Compute the mod for the nazelle and wind angles\n",
    "bdd_data.angle_mod()\n",
    "#Interpolate the missing values\n",
    "bdd_data.interpolate_power()\n",
    "#Values smaller than 0 are set to 0\n",
    "bdd_data.cap_power_to_zero()\n",
    "#Normalize Patv feature to [0,1]\n",
    "bdd_data.normalize_power(min=0, max=1, method= \"MinMaxScaler\")\n",
    "#Convert df to matrix form, where only Patv is included. Then split into train, validation and test\n",
    "#The matrix contains the subset of the time series for ALL nodes, so an (TxN matrix)\n",
    "train, val, test = bdd_data.split_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.828863400Z",
     "start_time": "2024-06-29T22:23:40.810918200Z"
    }
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(42)\n",
    "# consider a p percentage of the data\n",
    "p = 1.00\n",
    "train_mask = np.random.choice(train.shape[1], int(train.shape[1] * p), replace=False)\n",
    "val_mask = np.random.choice(val.shape[1], int(val.shape[1] * p), replace=False)\n",
    "test_mask = np.random.choice(test.shape[1], int(test.shape[1] * p), replace=False)\n",
    "\n",
    "train = train[:, train_mask]\n",
    "val = val[:, val_mask]\n",
    "test = test[:, test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.854039800Z",
     "start_time": "2024-06-29T22:23:40.835845900Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomBDD_Dataset(data.Dataset):\n",
    "    def __init__(self, dataset, observation_window=12, forecast_window=12, starting_turbine = 0,  ending_turbine=133):\n",
    "        self.observation_window = observation_window\n",
    "        self.forecast_window = forecast_window\n",
    "        length = eval(f'len({dataset}[0])')#Retrieves length of dataset\n",
    "        bdd_data.get_observation_forecasting_window(time_series_len=length, observation_steps=self.observation_window, forecast_steps=self.forecast_window)#Generates obs window\n",
    "        self.window_of_interest =  bdd_data.sliding_indices[str(self.observation_window)+\",\"+str(self.forecast_window)]#Retrieves windows\n",
    "        self.starting_turbine = starting_turbine\n",
    "        self.ending_turbine = ending_turbine  \n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_of_interest)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = self.window_of_interest[idx]\n",
    "        if self.dataset == \"train\":\n",
    "            features = train[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]]\n",
    "            labels = train[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]]\n",
    "        elif self.dataset == \"val\":\n",
    "            features = val[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]]\n",
    "            labels = val[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]]\n",
    "        elif self.dataset == \"test\":\n",
    "            features = test[self.starting_turbine:self.ending_turbine+1,window[0]:window[1]]\n",
    "            labels = test[self.starting_turbine:self.ending_turbine+1,window[1]:window[2]]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return torch.from_numpy(features).float(), torch.from_numpy(labels).float()\n",
    "    \n",
    "obs_window = 12\n",
    "forecast_window = 12\n",
    "batch_size = 100\n",
    "num_nodes = 134\n",
    "\n",
    "train_dataset = CustomBDD_Dataset(\"train\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "train_loader = data.DataLoader(train_dataset, shuffle=True, batch_size = batch_size)\n",
    "val_dataset = CustomBDD_Dataset(\"val\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "val_loader = data.DataLoader(val_dataset, shuffle=True, batch_size = batch_size)\n",
    "test_dataset = CustomBDD_Dataset(\"test\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "test_loader = data.DataLoader(test_dataset, shuffle=True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.863317Z",
     "start_time": "2024-06-29T22:23:40.856034400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([100, 134, 12])\n",
      "y.shape=torch.Size([100, 134, 12])\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "print(f\"{x.shape=}\\n{y.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.920462500Z",
     "start_time": "2024-06-29T22:23:40.864314500Z"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.read_gml('../graph/data/spatial_graph_2000.gml')\n",
    "adj_mat = nx.adjacency_matrix(G)\n",
    "adj_mat = nx.to_numpy_array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.924969500Z",
     "start_time": "2024-06-29T22:23:40.922457300Z"
    }
   },
   "outputs": [],
   "source": [
    "S = normalize_adjacency(torch.tensor(adj_mat)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.930334400Z",
     "start_time": "2024-06-29T22:23:40.928828900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 134)\n"
     ]
    }
   ],
   "source": [
    "print(adj_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.942823900Z",
     "start_time": "2024-06-29T22:23:40.938312900Z"
    }
   },
   "outputs": [],
   "source": [
    "class GCNNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, matrix_powers, order):\n",
    "        super(GCNNLayer, self).__init__()\n",
    "        self.matrix_powers = matrix_powers\n",
    "        self.order = order\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(in_features, out_features, order+1))\n",
    "        # use Xavier initialization to match variance of input with output\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def forward(self, features):\n",
    "        batch_size = features.size(0)\n",
    "        output_dim = self.weights.size(1)\n",
    "        device = features.device\n",
    "\n",
    "        out = torch.zeros((batch_size, features.size(1), output_dim), device=device)\n",
    "        for k in range(self.order+1):\n",
    "            weighted = torch.bmm(features, self.weights[:, :, k].unsqueeze(0).repeat(batch_size, 1, 1))\n",
    "            shifted = torch.bmm(self.matrix_powers[k].unsqueeze(0).repeat(batch_size, 1, 1).to(device), weighted)\n",
    "            out += shifted\n",
    "        return out\n",
    "\n",
    "# Inputs must be sized [num_nodes, obs_size] and outputs will be [num_nodes, pred_size]\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hid_sizes, shift, order):\n",
    "        super(GCNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # compute matrix shift\n",
    "        matrix_powers = [torch.matrix_power(shift, k).float() for k in range(order+1)]\n",
    "        # input layer of size obs_size\n",
    "        self.layers.append(GCNNLayer(obs_window, hid_sizes[0], matrix_powers, order))\n",
    "        # num_hid hidden layers of size hid_size\n",
    "        for i in range(len(hid_sizes) - 1):\n",
    "            self.layers.append(GCNNLayer(hid_sizes[i], hid_sizes[i + 1], matrix_powers, order))\n",
    "\n",
    "    def forward(self, features):\n",
    "        temp = features\n",
    "        for layer in self.layers[:-1]:\n",
    "            # use relu activation function\n",
    "            temp = F.relu(layer(temp))\n",
    "        return self.layers[-1](temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:23:40.950076500Z",
     "start_time": "2024-06-29T22:23:40.946813300Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = torch.nn.functional.mse_loss(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate_epoch(model, loader, device='cpu'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = torch.nn.functional.mse_loss(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, file_name, num_epochs=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    pointers = []\n",
    "    best_loss = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "        val_loss = evaluate_epoch(model, val_loader, device=device)\n",
    "\n",
    "        # If model is better, export new model pointer.\n",
    "        if best_loss is None or val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            pointers.append(epoch)\n",
    "            torch.save(model.state_dict(), f'{file_name}_v{epoch}.pth')\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"epoch: {epoch}\\ttraining loss: {train_loss:.4f}\\tvalidation loss: {val_loss:.4f}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    print(f'Model training took {elapsed_time:.3f} seconds')\n",
    "\n",
    "    return train_losses, val_losses, pointers, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T22:24:28.477228600Z",
     "start_time": "2024-06-29T22:23:40.954065600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created GCNN model with 1792 parameters:\n",
      "layers.0.weights torch.Size([12, 16, 2])\n",
      "layers.1.weights torch.Size([16, 16, 2])\n",
      "layers.2.weights torch.Size([16, 16, 2])\n",
      "layers.3.weights torch.Size([16, 12, 2])\n",
      "epoch: 1\ttraining loss: 0.0884\tvalidation loss: 0.0616\n",
      "epoch: 2\ttraining loss: 0.0763\tvalidation loss: 0.0639\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(name, param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m train_losses, val_losses, pointers, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Run the best model on the test set, export accuracy\u001b[39;00m\n\u001b[1;32m     20\u001b[0m best_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpointers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[20], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, file_name, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate_epoch(model, val_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# If model is better, export new model pointer.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(outputs, y)\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/cse-ml4gd/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cse-ml4gd/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 39\u001b[0m, in \u001b[0;36mGCNN.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     36\u001b[0m temp \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# use relu activation function\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     temp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](temp)\n",
      "File \u001b[0;32m~/miniconda3/envs/cse-ml4gd/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cse-ml4gd/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mGCNNLayer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     15\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((batch_size, features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), output_dim), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     weighted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(features, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepeat(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     18\u001b[0m     shifted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatrix_powers[k]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), weighted)\n\u001b[1;32m     19\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m shifted\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "architectures = [[16, 16, 16, forecast_window], [8, 8, 8, forecast_window]] # [16, 8, forecast_window], [16, 8, 4, forecast_window]\n",
    "order = 1\n",
    "num_epochs = 10\n",
    "\n",
    "for architecture in architectures:\n",
    "        model = GCNN(architecture, S, order).to(device)\n",
    "        architecture_string = '[' + ','.join(map(str, architecture)) + ']'\n",
    "        file_name = f'../results/gcnn_e={num_epochs}_d={p}_k={order}{architecture_string}'\n",
    "\n",
    "        pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Created GCNN model with {pytorch_total_params} parameters:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data.size())\n",
    "\n",
    "        # Train the model\n",
    "        train_losses, val_losses, pointers, elapsed_time = train_model(model, train_loader, val_loader, file_name, num_epochs=num_epochs)\n",
    "\n",
    "        # Run the best model on the test set, export accuracy\n",
    "        best_loc = f'{file_name}_v{pointers[-1]}.pth'\n",
    "        model.load_state_dict(torch.load(best_loc))\n",
    "        test_loss = evaluate_epoch(model, test_loader, device=device)\n",
    "        print(f\"Final test loss: {test_loss}\\n\")\n",
    "\n",
    "        # Export test accuracy\n",
    "        file_path = f'{file_name}.txt'\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(f\"{str(test_loss)}, {elapsed_time:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes\n",
    "bdd_data = BDD_dataset(\"../raw_data/BDDdata/\")\n",
    "#Add column with the timestep\n",
    "bdd_data.add_timestep_id()\n",
    "#Add flags for chaotic values\n",
    "bdd_data.tag_chaotic(replace=True)\n",
    "#Compute the mod for the nazelle and wind angles\n",
    "bdd_data.angle_mod()\n",
    "#Interpolate the missing values\n",
    "bdd_data.interpolate_power()\n",
    "#Values smaller than 0 are set to 0\n",
    "bdd_data.cap_power_to_zero()\n",
    "#Normalize Patv feature to [0,1]\n",
    "bdd_data.normalize_power(min=0, max=1, method= \"MinMaxScaler\")\n",
    "#Convert df to matrix form, where only Patv is included. Then split into train, validation and test\n",
    "#The matrix contains the subset of the time series for ALL nodes, so an (TxN matrix)\n",
    "_, _, test = bdd_data.split_df()\n",
    "\n",
    "test_dataset_nan = CustomBDD_Dataset(\"test\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "test_loader_nan = data.DataLoader(test_dataset, shuffle=False, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes\n",
    "bdd_data = BDD_dataset(\"../raw_data/BDDdata/\")\n",
    "#Add column with the timestep\n",
    "bdd_data.add_timestep_id()\n",
    "#Add flags for chaotic values\n",
    "bdd_data.tag_chaotic(replace=True)\n",
    "#Compute the mod for the nazelle and wind angles\n",
    "bdd_data.angle_mod()\n",
    "#Interpolate the missing values\n",
    "bdd_data.interpolate_power()\n",
    "#Values smaller than 0 are set to 0\n",
    "bdd_data.cap_power_to_zero()\n",
    "#Normalize Patv feature to [0,1]\n",
    "bdd_data.normalize_power(min=0, max=1, method= \"MinMaxScaler\")\n",
    "#Convert df to matrix form, where only Patv is included. Then split into train, validation and test\n",
    "#The matrix contains the subset of the time series for ALL nodes, so an (TxN matrix)\n",
    "_, _, test = bdd_data.split_df()\n",
    "\n",
    "test_dataset_interpolated = CustomBDD_Dataset(\"test\",observation_window=obs_window,forecast_window=forecast_window)\n",
    "test_loader_interpolated = data.DataLoader(test_dataset, shuffle=False, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13360085495309934\n",
      "0.083043375732525\n",
      "0.10187376062903139\n"
     ]
    }
   ],
   "source": [
    "# Helper functions\n",
    "class SDELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SDELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        error = input - target\n",
    "        mean_error = torch.mean(error)\n",
    "        return torch.sqrt(torch.mean((error - mean_error) ** 2))\n",
    "    \n",
    "class MaskedLoss(nn.Module):\n",
    "    def __init__(self, criterion):\n",
    "        super(MaskedLoss, self).__init__()\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        # Create a mask that is 1 for non-NaN entries and 0 for NaN entries\n",
    "        isnan = torch.isnan(target)\n",
    "        mask = ~isnan\n",
    "        # Apply the mask to only keep non-NaN elements\n",
    "        out = prediction[mask]\n",
    "        tar = target[mask]\n",
    "        if torch.any(torch.isnan(out)):\n",
    "            print(\"X\")\n",
    "        # Calculate MSE Loss on non-NaN elements\n",
    "        return self.criterion(out, tar)\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, interpolated_loader, nan_loader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        nan_iter = iter(nan_loader)\n",
    "        for x, _ in interpolated_loader:\n",
    "            _, y = next(nan_iter)\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(interpolated_loader)\n",
    "\n",
    "# GCNN\n",
    "architecture = [8,8,12]\n",
    "model = GCNN(architecture, S, order).to(device)\n",
    "path = \"results/gcnn_d=1.00/gcnn_e=10_d=1.0_k=1[8,8,12]_v2.pth\"\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "\n",
    "print(np.sqrt(evaluate_epoch(model, test_loader_interpolated, test_loader_nan, MaskedLoss(nn.MSELoss()), device=device)))\n",
    "print(evaluate_epoch(model, test_loader_interpolated, test_loader_nan, MaskedLoss(nn.L1Loss()), device=device))\n",
    "print(evaluate_epoch(model, test_loader_interpolated, test_loader_nan, MaskedLoss(SDELoss()), device=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse-ml4gd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
